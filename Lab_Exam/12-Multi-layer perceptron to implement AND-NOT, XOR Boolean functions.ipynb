{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3bfd6aa",
   "metadata": {},
   "source": [
    "# 12. Multi-layer perceptron to implement AND-NOT, XOR Boolean functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecee0625",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6263f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activation function (sigmoid) and its derivative\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d7c27c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training data for AND-NOT function\n",
    "X_and_not = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y_and_not = np.array([[0], [0], [1], [0]])\n",
    "\n",
    "# Define the training data for XOR function\n",
    "X_xor = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y_xor = np.array([[0], [1], [1], [0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7f1e6b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Multi-layer Perceptron class with one hidden layer\n",
    "class MLP:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        # Initialize weights for input to hidden layer\n",
    "        self.weights_input = np.random.rand(input_size, hidden_size)\n",
    "        \n",
    "        # Initialize weights for hidden to output layer\n",
    "        self.weights_output = np.random.rand(hidden_size, output_size)\n",
    "        \n",
    "        # Initialize biases for hidden layer\n",
    "        self.bias_hidden = np.random.rand(1, hidden_size)\n",
    "        \n",
    "        # Initialize biases for output layer\n",
    "        self.bias_output = np.random.rand(1, output_size)\n",
    "\n",
    "    def forward(self, X):\n",
    "        # Forward pass through the hidden layer\n",
    "        self.hidden = sigmoid(np.dot(X, self.weights_input) + self.bias_hidden)\n",
    "        \n",
    "        # Forward pass through the output layer\n",
    "        self.output = sigmoid(np.dot(self.hidden, self.weights_output) + self.bias_output)\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, X, y, output):\n",
    "        # Calculate the error for the output layer\n",
    "        output_error = y - output\n",
    "        output_delta = output_error * sigmoid_derivative(output)\n",
    "\n",
    "        # Calculate the error for the hidden layer\n",
    "        hidden_error = output_delta.dot(self.weights_output.T)\n",
    "        hidden_delta = hidden_error * sigmoid_derivative(self.hidden)\n",
    "\n",
    "        # Update weights and biases\n",
    "        self.weights_output += self.hidden.T.dot(output_delta)\n",
    "        self.weights_input += X.T.dot(hidden_delta)\n",
    "        self.bias_hidden += np.sum(hidden_delta, axis=0, keepdims=True)\n",
    "        self.bias_output += np.sum(output_delta, axis=0, keepdims=True)\n",
    "\n",
    "    def train(self, X, y, epochs):\n",
    "        for _ in range(epochs):\n",
    "            output = self.forward(X)\n",
    "            self.backward(X, y, output)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return (self.forward(X) > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e73d8a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the MLP for AND-NOT function\n",
    "mlp_and_not = MLP(input_size=2, hidden_size=4, output_size=1)\n",
    "mlp_and_not.train(X_and_not, y_and_not, epochs=5000)\n",
    "\n",
    "# Training the MLP for XOR function\n",
    "mlp_xor = MLP(input_size=2, hidden_size=4, output_size=1)\n",
    "mlp_xor.train(X_xor, y_xor, epochs=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "90d52ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AND-NOT Function Predictions:\n",
      "[[0]\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      "\n",
      "XOR Function Predictions:\n",
      "[[0]\n",
      " [1]\n",
      " [1]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "# Print training results\n",
    "print(\"AND-NOT Function Predictions:\")\n",
    "print(mlp_and_not.predict(X_and_not))\n",
    "\n",
    "print(\"\\nXOR Function Predictions:\")\n",
    "print(mlp_xor.predict(X_xor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4dc33a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AND-NOT Function Prediction for input [0, 1]:\n",
      "[[0]]\n",
      "\n",
      "XOR Function Prediction for input [1, 0]:\n",
      "[[1]]\n"
     ]
    }
   ],
   "source": [
    "# Manually test specific input values\n",
    "and_not_test_input = np.array([[0, 1]])\n",
    "xor_test_input = np.array([[1, 0]])\n",
    "\n",
    "print(\"\\nAND-NOT Function Prediction for input [0, 1]:\")\n",
    "print(mlp_and_not.predict(and_not_test_input))\n",
    "\n",
    "print(\"\\nXOR Function Prediction for input [1, 0]:\")\n",
    "print(mlp_xor.predict(xor_test_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "79b6bbbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function sum in module numpy:\n",
      "\n",
      "sum(a, axis=None, dtype=None, out=None, keepdims=<no value>, initial=<no value>, where=<no value>)\n",
      "    Sum of array elements over a given axis.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Elements to sum.\n",
      "    axis : None or int or tuple of ints, optional\n",
      "        Axis or axes along which a sum is performed.  The default,\n",
      "        axis=None, will sum all of the elements of the input array.  If\n",
      "        axis is negative it counts from the last to the first axis.\n",
      "    \n",
      "        .. versionadded:: 1.7.0\n",
      "    \n",
      "        If axis is a tuple of ints, a sum is performed on all of the axes\n",
      "        specified in the tuple instead of a single axis or all the axes as\n",
      "        before.\n",
      "    dtype : dtype, optional\n",
      "        The type of the returned array and of the accumulator in which the\n",
      "        elements are summed.  The dtype of `a` is used by default unless `a`\n",
      "        has an integer dtype of less precision than the default platform\n",
      "        integer.  In that case, if `a` is signed then the platform integer\n",
      "        is used while if `a` is unsigned then an unsigned integer of the\n",
      "        same precision as the platform integer is used.\n",
      "    out : ndarray, optional\n",
      "        Alternative output array in which to place the result. It must have\n",
      "        the same shape as the expected output, but the type of the output\n",
      "        values will be cast if necessary.\n",
      "    keepdims : bool, optional\n",
      "        If this is set to True, the axes which are reduced are left\n",
      "        in the result as dimensions with size one. With this option,\n",
      "        the result will broadcast correctly against the input array.\n",
      "    \n",
      "        If the default value is passed, then `keepdims` will not be\n",
      "        passed through to the `sum` method of sub-classes of\n",
      "        `ndarray`, however any non-default value will be.  If the\n",
      "        sub-class' method does not implement `keepdims` any\n",
      "        exceptions will be raised.\n",
      "    initial : scalar, optional\n",
      "        Starting value for the sum. See `~numpy.ufunc.reduce` for details.\n",
      "    \n",
      "        .. versionadded:: 1.15.0\n",
      "    \n",
      "    where : array_like of bool, optional\n",
      "        Elements to include in the sum. See `~numpy.ufunc.reduce` for details.\n",
      "    \n",
      "        .. versionadded:: 1.17.0\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    sum_along_axis : ndarray\n",
      "        An array with the same shape as `a`, with the specified\n",
      "        axis removed.   If `a` is a 0-d array, or if `axis` is None, a scalar\n",
      "        is returned.  If an output array is specified, a reference to\n",
      "        `out` is returned.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    ndarray.sum : Equivalent method.\n",
      "    \n",
      "    add.reduce : Equivalent functionality of `add`.\n",
      "    \n",
      "    cumsum : Cumulative sum of array elements.\n",
      "    \n",
      "    trapz : Integration of array values using the composite trapezoidal rule.\n",
      "    \n",
      "    mean, average\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    Arithmetic is modular when using integer types, and no error is\n",
      "    raised on overflow.\n",
      "    \n",
      "    The sum of an empty array is the neutral element 0:\n",
      "    \n",
      "    >>> np.sum([])\n",
      "    0.0\n",
      "    \n",
      "    For floating point numbers the numerical precision of sum (and\n",
      "    ``np.add.reduce``) is in general limited by directly adding each number\n",
      "    individually to the result causing rounding errors in every step.\n",
      "    However, often numpy will use a  numerically better approach (partial\n",
      "    pairwise summation) leading to improved precision in many use-cases.\n",
      "    This improved precision is always provided when no ``axis`` is given.\n",
      "    When ``axis`` is given, it will depend on which axis is summed.\n",
      "    Technically, to provide the best speed possible, the improved precision\n",
      "    is only used when the summation is along the fast axis in memory.\n",
      "    Note that the exact precision may vary depending on other parameters.\n",
      "    In contrast to NumPy, Python's ``math.fsum`` function uses a slower but\n",
      "    more precise approach to summation.\n",
      "    Especially when summing a large number of lower precision floating point\n",
      "    numbers, such as ``float32``, numerical errors can become significant.\n",
      "    In such cases it can be advisable to use `dtype=\"float64\"` to use a higher\n",
      "    precision for the output.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.sum([0.5, 1.5])\n",
      "    2.0\n",
      "    >>> np.sum([0.5, 0.7, 0.2, 1.5], dtype=np.int32)\n",
      "    1\n",
      "    >>> np.sum([[0, 1], [0, 5]])\n",
      "    6\n",
      "    >>> np.sum([[0, 1], [0, 5]], axis=0)\n",
      "    array([0, 6])\n",
      "    >>> np.sum([[0, 1], [0, 5]], axis=1)\n",
      "    array([1, 5])\n",
      "    >>> np.sum([[0, 1], [np.nan, 5]], where=[False, True], axis=1)\n",
      "    array([1., 5.])\n",
      "    \n",
      "    If the accumulator is too small, overflow occurs:\n",
      "    \n",
      "    >>> np.ones(128, dtype=np.int8).sum(dtype=np.int8)\n",
      "    -128\n",
      "    \n",
      "    You can also start the sum with a value other than zero:\n",
      "    \n",
      "    >>> np.sum([10], initial=5)\n",
      "    15\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ed3921",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
